1. Vao spark master
docker cp -L schema.py spark-master:/opt/spark-apps/py-spark/schema.py
docker cp -L spark_streaming_function.py spark-master:/opt/spark-apps/py-spark/spark_streaming_function.py
docker cp -L read_kafka.py spark-master:/opt/spark-apps/py-spark/read_kafka.py
docker-compose exec spark-master /opt/spark/bin/spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2 /opt/spark-apps/py-spark/read_kafka.py

2. vao namenode
hdfs dfs -mkdir -p /mydata/output
hdfs dfs -rmdir /mydata/output